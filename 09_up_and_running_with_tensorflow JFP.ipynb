{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.Variable(3, name=\"x\")\n",
    "y = tf.Variable(4, name=\"y\")\n",
    "f = x*x*y + y + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(x.initializer)\n",
    "sess.run(y.initializer)\n",
    "result = sess.run(f)\n",
    "sess.close()\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:  # with a context\n",
    "    x.initializer.run() # equivalent to tf.get_default_session().run(x.initializer)\n",
    "    y.initializer.run()\n",
    "    result = f.eval()\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# prepare an init node\n",
    "with tf.Session() as sess:\n",
    "    init.run() # actually initialize all the variables\n",
    "    result = f.eval()\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "# preferable within the jupyter\n",
    "\n",
    "sess = tf.InteractiveSession() # by doing this we avoid the need of a context\n",
    "init.run()\n",
    "result = f.eval()\n",
    "print(result)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Managing graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = tf.Variable(1)\n",
    "x1.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    x2 = tf.Variable(2)\n",
    "print(x2.graph is graph)\n",
    "print(x2.graph is tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression with Tensor flow\n",
    "## With normal equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['DESCR', 'target', 'feature_names', 'data'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "m, n = housing.data.shape\n",
    "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data]\n",
    "X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "XT = tf.transpose(X)\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT,X)),XT),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run() # actually initialize all the variables\n",
    "    theta_val = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -3.74651413e+01],\n",
       "       [  4.35734153e-01],\n",
       "       [  9.33829229e-03],\n",
       "       [ -1.06622010e-01],\n",
       "       [  6.44106984e-01],\n",
       "       [ -4.25131839e-06],\n",
       "       [ -3.77322501e-03],\n",
       "       [ -4.26648885e-01],\n",
       "       [ -4.40514028e-01]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 7.25239\n",
      "Epoch 100 MSE = 0.726437\n",
      "Epoch 200 MSE = 0.597995\n",
      "Epoch 300 MSE = 0.578571\n",
      "Epoch 400 MSE = 0.565446\n",
      "Epoch 500 MSE = 0.555666\n",
      "Epoch 600 MSE = 0.548332\n",
      "Epoch 700 MSE = 0.542808\n",
      "Epoch 800 MSE = 0.538628\n",
      "Epoch 900 MSE = 0.535452\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph() # clear the graph\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = eta = 0.01\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_housing_data = scaler.fit_transform(housing.data)\n",
    "scaled_housing_data_plus_bias = np.c_[np.ones((m, 1)), scaled_housing_data]\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "\n",
    "inputs = n+1\n",
    "outputs = 1\n",
    "\n",
    "theta = tf.Variable(tf.random_uniform([inputs, outputs], -1.0, 1.0), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "#mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "mse = tf.losses.mean_squared_error(y, y_pred)\n",
    "gradients = 2 / m * tf.matmul(tf.transpose(X),error)\n",
    "training_op = tf.assign(theta, theta - eta * gradients)\n",
    "\n",
    "init = tf.global_variables_initializer() # need one again as we destroyed the graph\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init) # actually initialize all the variables\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    theta_val = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.06855226e+00],\n",
       "       [  7.13241160e-01],\n",
       "       [  1.21060446e-01],\n",
       "       [ -5.18330256e-04],\n",
       "       [  6.67099729e-02],\n",
       "       [ -2.15252652e-03],\n",
       "       [ -3.70401554e-02],\n",
       "       [ -9.92338717e-01],\n",
       "       [ -9.47266042e-01]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## automatic gradients computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 13.6693\n",
      "Epoch 100 MSE = 0.785947\n",
      "Epoch 200 MSE = 0.598594\n",
      "Epoch 300 MSE = 0.575718\n",
      "Epoch 400 MSE = 0.561343\n",
      "Epoch 500 MSE = 0.551024\n",
      "Epoch 600 MSE = 0.543582\n",
      "Epoch 700 MSE = 0.538215\n",
      "Epoch 800 MSE = 0.534343\n",
      "Epoch 900 MSE = 0.53155\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph() # clear the graph\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = eta = 0.01\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_housing_data = scaler.fit_transform(housing.data)\n",
    "scaled_housing_data_plus_bias = np.c_[np.ones((m, 1)), scaled_housing_data]\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "\n",
    "inputs = n+1\n",
    "outputs = 1\n",
    "\n",
    "theta = tf.Variable(tf.random_uniform([inputs, outputs], -1.0, 1.0), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "gradients = tf.gradients(mse, [theta])[0]\n",
    "training_op = tf.assign(theta, theta - eta * gradients)\n",
    "\n",
    "init = tf.global_variables_initializer() # need one again as we destroyed the graph\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init) # actually initialize all the variables\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    theta_val = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.06855226],\n",
       "       [ 0.78753787],\n",
       "       [ 0.13936418],\n",
       "       [-0.13271001],\n",
       "       [ 0.17242327],\n",
       "       [ 0.00354152],\n",
       "       [-0.04017262],\n",
       "       [-0.78913975],\n",
       "       [-0.7523182 ]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with automatic optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 8.18415\n",
      "Epoch 100 MSE = 0.534615\n",
      "Epoch 200 MSE = 0.525673\n",
      "Epoch 300 MSE = 0.524501\n",
      "Epoch 400 MSE = 0.524345\n",
      "Epoch 500 MSE = 0.524324\n",
      "Epoch 600 MSE = 0.524321\n",
      "Epoch 700 MSE = 0.524321\n",
      "Epoch 800 MSE = 0.524321\n",
      "Epoch 900 MSE = 0.524321\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph() # clear the graph\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = eta = 0.01\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_housing_data = scaler.fit_transform(housing.data)\n",
    "scaled_housing_data_plus_bias = np.c_[np.ones((m, 1)), scaled_housing_data]\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "\n",
    "inputs = n+1\n",
    "outputs = 1\n",
    "\n",
    "theta = tf.Variable(tf.random_uniform([inputs, outputs], -1.0, 1.0), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "#mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "mse = tf.losses.mean_squared_error(y, y_pred)\n",
    "#gradients = tf.gradients(mse, [theta])[0] # no need to tell what the gradients are\n",
    "# optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate,momentum=0.9)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer() # need one again as we destroyed the graph\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init) # actually initialize all the variables\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    theta_val = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.06855774],\n",
       "       [ 0.82963252],\n",
       "       [ 0.11875407],\n",
       "       [-0.26555178],\n",
       "       [ 0.30571687],\n",
       "       [-0.00450229],\n",
       "       [-0.03932676],\n",
       "       [-0.89985549],\n",
       "       [-0.87051237]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mini batch gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 0.481366\n",
      "Epoch 100 MSE = 0.924752\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph() # clear the graph\n",
    "\n",
    "n_epochs = 200\n",
    "learning_rate = 0.01\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_housing_data = scaler.fit_transform(housing.data)\n",
    "scaled_housing_data_plus_bias = np.c_[np.ones((m, 1)), scaled_housing_data]\n",
    "\n",
    "inputs = n+1\n",
    "outputs = 1\n",
    "\n",
    "#X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "X = tf.placeholder(tf.float32, shape=(None, inputs), name=\"X\")\n",
    "#y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, outputs), name=\"X\")\n",
    "\n",
    "\n",
    "theta = tf.Variable(tf.random_uniform([inputs, outputs], -1.0, 1.0), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "# gradients = tf.gradients(mse, [theta])[0] # no need to tell what the gradients are\n",
    "# optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer() # need one again as we destroyed the graph\n",
    "\n",
    "def fetch_batch(epoch, batch_index, batch_size):\n",
    "    np.random.seed(epoch)\n",
    "    indices = np.random.permutation(m) \n",
    "    start = batch_index*batch_size\n",
    "    end= start + batch_size\n",
    "    X_batch = scaled_housing_data_plus_bias[indices[start:end]]\n",
    "    y_batch = housing.target.reshape(-1, 1)[indices[start:end]] \n",
    "    return X_batch, y_batch\n",
    "    return X_batch, y_batch\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init) # actually initialize all the variables\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval(feed_dict={X: X_batch, y: y_batch}))\n",
    "            pass\n",
    "    theta_val = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.07506418],\n",
       "       [ 0.83795285],\n",
       "       [ 0.11016226],\n",
       "       [-0.2480446 ],\n",
       "       [ 0.28836557],\n",
       "       [-0.01022439],\n",
       "       [-0.03968161],\n",
       "       [-0.90265501],\n",
       "       [-0.86845046]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adding a saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 5.69436\n",
      "Epoch 100 MSE = 0.527871\n",
      "Epoch 200 MSE = 0.524653\n",
      "Epoch 300 MSE = 0.524363\n",
      "Epoch 400 MSE = 0.524327\n",
      "Epoch 500 MSE = 0.524322\n",
      "Epoch 600 MSE = 0.524321\n",
      "Epoch 700 MSE = 0.524321\n",
      "Epoch 800 MSE = 0.524321\n",
      "Epoch 900 MSE = 0.524321\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph() # clear the graph\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = eta = 0.01\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_housing_data = scaler.fit_transform(housing.data)\n",
    "scaled_housing_data_plus_bias = np.c_[np.ones((m, 1)), scaled_housing_data]\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "\n",
    "inputs = n+1\n",
    "outputs = 1\n",
    "\n",
    "theta = tf.Variable(tf.random_uniform([inputs, outputs], -1.0, 1.0), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate,momentum=0.9)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer() # need one again as we destroyed the graph\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init) # actually initialize all the variables\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "            save_path = saver.save(sess, \"/tmp/my_model.ckpt\")\n",
    "        sess.run(training_op)\n",
    "    theta_val = theta.eval()\n",
    "    save_path = saver.save(sess, \"/tmp/my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = b\"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.22047291788230816&quot;).pbtxt = 'node {\\n  name: &quot;X&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 20640\\n          }\\n          dim {\\n            size: 9\\n          }\\n        }\\n        tensor_content: &quot;<stripped 743040 bytes>&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 20640\\n          }\\n          dim {\\n            size: 1\\n          }\\n        }\\n        tensor_content: &quot;<stripped 82560 bytes>&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\t\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;random_uniform/max&quot;\\n  input: &quot;random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;random_uniform/RandomUniform&quot;\\n  input: &quot;random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;random_uniform/mul&quot;\\n  input: &quot;random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;theta&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 9\\n        }\\n        dim {\\n          size: 1\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;theta/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;theta&quot;\\n  input: &quot;random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@theta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;theta/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;theta&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@theta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;predictions&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;X&quot;\\n  input: &quot;theta/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;predictions&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Square&quot;\\n  op: &quot;Square&quot;\\n  input: &quot;sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;mse&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;Square&quot;\\n  input: &quot;Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape&quot;\\n  input: &quot;gradients/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/Fill&quot;\\n  input: &quot;gradients/mse_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Tile/multiples&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\240P\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;gradients/mse_grad/Reshape&quot;\\n  input: &quot;gradients/mse_grad/Tile/multiples&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\240P\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Prod&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;gradients/mse_grad/Shape&quot;\\n  input: &quot;gradients/mse_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Prod_1&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;gradients/mse_grad/Shape_1&quot;\\n  input: &quot;gradients/mse_grad/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;gradients/mse_grad/Prod_1&quot;\\n  input: &quot;gradients/mse_grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/floordiv&quot;\\n  op: &quot;FloorDiv&quot;\\n  input: &quot;gradients/mse_grad/Prod&quot;\\n  input: &quot;gradients/mse_grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;gradients/mse_grad/floordiv&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;gradients/mse_grad/Tile&quot;\\n  input: &quot;gradients/mse_grad/Cast&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Square_grad/mul/x&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^gradients/mse_grad/truediv&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 2.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Square_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/Square_grad/mul/x&quot;\\n  input: &quot;sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Square_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/mse_grad/truediv&quot;\\n  input: &quot;gradients/Square_grad/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\240P\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\240P\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/sub_grad/Shape&quot;\\n  input: &quot;gradients/sub_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/Square_grad/mul_1&quot;\\n  input: &quot;gradients/sub_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/sub_grad/Sum&quot;\\n  input: &quot;gradients/sub_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/Square_grad/mul_1&quot;\\n  input: &quot;gradients/sub_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;gradients/sub_grad/Sum_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/sub_grad/Neg&quot;\\n  input: &quot;gradients/sub_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/sub_grad/Reshape&quot;\\n  input: &quot;^gradients/sub_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/sub_grad/Reshape&quot;\\n  input: &quot;^gradients/sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/sub_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/sub_grad/Reshape_1&quot;\\n  input: &quot;^gradients/sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/sub_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/predictions_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/sub_grad/tuple/control_dependency&quot;\\n  input: &quot;theta/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/predictions_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;X&quot;\\n  input: &quot;gradients/sub_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/predictions_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/predictions_grad/MatMul&quot;\\n  input: &quot;^gradients/predictions_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/predictions_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/predictions_grad/MatMul&quot;\\n  input: &quot;^gradients/predictions_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/predictions_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/predictions_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/predictions_grad/MatMul_1&quot;\\n  input: &quot;^gradients/predictions_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/predictions_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;theta/Momentum/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@theta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 9\\n          }\\n          dim {\\n            size: 1\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;theta/Momentum&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@theta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 9\\n        }\\n        dim {\\n          size: 1\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;theta/Momentum/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;theta/Momentum&quot;\\n  input: &quot;theta/Momentum/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@theta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;theta/Momentum/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;theta/Momentum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@theta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Momentum/learning_rate&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.009999999776482582\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Momentum/momentum&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.8999999761581421\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Momentum/update_theta/ApplyMomentum&quot;\\n  op: &quot;ApplyMomentum&quot;\\n  input: &quot;theta&quot;\\n  input: &quot;theta/Momentum&quot;\\n  input: &quot;Momentum/learning_rate&quot;\\n  input: &quot;gradients/predictions_grad/tuple/control_dependency_1&quot;\\n  input: &quot;Momentum/momentum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@theta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Momentum&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^Momentum/update_theta/ApplyMomentum&quot;\\n}\\nnode {\\n  name: &quot;init&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^theta/Assign&quot;\\n  input: &quot;^theta/Momentum/Assign&quot;\\n}\\nnode {\\n  name: &quot;save/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;model&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        string_val: &quot;theta&quot;\\n        string_val: &quot;theta/Momentum&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2&quot;\\n  op: &quot;SaveV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/SaveV2/tensor_names&quot;\\n  input: &quot;save/SaveV2/shape_and_slices&quot;\\n  input: &quot;theta&quot;\\n  input: &quot;theta/Momentum&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;^save/SaveV2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@save/Const&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;theta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2/tensor_names&quot;\\n  input: &quot;save/RestoreV2/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;theta&quot;\\n  input: &quot;save/RestoreV2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@theta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_1/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;theta/Momentum&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_1/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_1&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_1/tensor_names&quot;\\n  input: &quot;save/RestoreV2_1/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_1&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;theta/Momentum&quot;\\n  input: &quot;save/RestoreV2_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@theta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/restore_all&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^save/Assign&quot;\\n  input: &quot;^save/Assign_1&quot;\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.22047291788230816&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exercices - Logistic regression with moon dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAETCAYAAADzrOu5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f63c6bb0860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_moons, y_moons = make_moons(n_samples=1000, noise=0.15, random_state=42)\n",
    "\n",
    "def plot_dataset(X, y, axes):\n",
    "    plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"bs\")\n",
    "    plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"g^\")\n",
    "    plt.axis(axes)\n",
    "    plt.grid(True, which='both')\n",
    "    plt.xlabel(r\"$x_1$\", fontsize=20)\n",
    "    plt.ylabel(r\"$x_2$\", fontsize=20, rotation=0)\n",
    "\n",
    "plot_dataset(X_moons, y_moons, [-1.5, 2.5, -1, 1.5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_moons.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_samples = X_moons.shape[0]\n",
    "nb_inputs = X_moons.shape[1]\n",
    "nb_outputs = 1\n",
    "\n",
    "X_moons_with_bias = np.c_[np.ones((nb_samples, 1)), X_moons]\n",
    "y_moons_column_vector = y_moons.reshape(-1, 1)\n",
    "\n",
    "# setting aside test \n",
    "test_ratio = 0.2\n",
    "test_size = int(nb_samples * test_ratio)\n",
    "X_train = X_moons_with_bias[:-test_size]\n",
    "X_test = X_moons_with_bias[-test_size:]\n",
    "y_train = y_moons_column_vector[:-test_size]\n",
    "y_test = y_moons_column_vector[-test_size:]\n",
    "\n",
    "nb_epoch = 10001\n",
    "batch_size = int(np.ceil(nb_samples/20))\n",
    "learning_rate = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_batch(X_train, y_train, batch_size):\n",
    "    rnd_indices = np.random.randint(0, len(X_train), batch_size)\n",
    "    X_batch = X_train[rnd_indices]\n",
    "    y_batch = y_train[rnd_indices]\n",
    "    return X_batch, y_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph() # clear the graph\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, nb_inputs+1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, nb_outputs), name=\"X\")\n",
    "theta = tf.Variable(tf.random_uniform([nb_inputs + 1, nb_outputs], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "logits = tf.matmul(X, theta, name=\"logits\")\n",
    "y_proba = 1 / (1 + tf.exp(-logits)) \n",
    "\n",
    "epsilon = 1e-7  # to avoid an overflow when computing the log\n",
    "#loss = -tf.reduce_mean(y * tf.log(y_proba + epsilon) + (1 - y) * tf.log(1 - y_proba + epsilon))\n",
    "loss = tf.losses.log_loss(y, y_proba)  # uses epsilon = 1e-7 by default\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer() # need one again as we destroyed the graph\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0  - loss:  0.71483\n",
      "Epoch  1000  - loss:  0.289051\n",
      "Epoch  2000  - loss:  0.28892\n",
      "Epoch  3000  - loss:  0.291406\n",
      "Epoch  4000  - loss:  0.28938\n",
      "Epoch  5000  - loss:  0.290563\n",
      "Epoch  6000  - loss:  0.288893\n",
      "Epoch  7000  - loss:  0.291874\n",
      "Epoch  8000  - loss:  0.289637\n",
      "Epoch  9000  - loss:  0.292659\n",
      "Epoch  10000  - loss:  0.290197\n"
     ]
    }
   ],
   "source": [
    "# main training loop\n",
    "\n",
    "nb_batch = int(np.ceil(X_train.shape[0]/batch_size))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(nb_epoch):\n",
    "        for i in range(nb_batch):\n",
    "            X_batch, y_batch = random_batch(X_train, y_train, batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val = loss.eval({X: X_test, y: y_test})\n",
    "        if epoch % 1000 == 0:\n",
    "            print(\"Epoch \", epoch, \" - loss: \", loss_val)\n",
    "    theta_best = theta.eval()\n",
    "    y_proba_val = y_proba.eval(feed_dict={X: X_test, y: y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.75932187],\n",
       "       [ 1.25270367],\n",
       "       [-5.43885756]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = (y_proba_val >= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False]], dtype=bool)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83333333333333337"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90909090909090906"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCSEkhfx//UL/faD80+AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f62e919e780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_idx = y_pred.reshape(-1) # a 1D array rather than a column vector\n",
    "plt.plot(X_test[y_pred_idx, 1], X_test[y_pred_idx, 2], 'go', label=\"Positive\")\n",
    "plt.plot(X_test[~y_pred_idx, 1], X_test[~y_pred_idx, 2], 'r^', label=\"Negative\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph() # clear the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def logistic_regression(X, y, seed=42, learning_rate=0.01):\n",
    "    n_inputs_including_bias = int(X.get_shape()[1])\n",
    "    with tf.name_scope(\"logistic_regression\"):\n",
    "        with tf.name_scope(\"model\"):\n",
    "            theta = tf.Variable(tf.random_uniform([n_inputs_including_bias, 1], -1.0, 1.0, seed=seed), name=\"theta\")\n",
    "            logits = tf.matmul(X, theta, name=\"logits\")\n",
    "            #y_proba = 1 / (1 + tf.exp(-logits)) \n",
    "            y_proba = tf.sigmoid(logits)\n",
    "\n",
    "        with tf.name_scope(\"learning\"):\n",
    "            loss = tf.losses.log_loss(y, y_proba)  # uses epsilon = 1e-7 by default\n",
    "            loss_summary = tf.summary.scalar('log_loss', loss)\n",
    "            optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "            training_op = optimizer.minimize(loss)\n",
    "    \n",
    "        with tf.name_scope(\"init\"):\n",
    "            init = tf.global_variables_initializer()\n",
    "        with tf.name_scope(\"save\"):\n",
    "            saver = tf.train.Saver()\n",
    "    \n",
    "    return y_proba, loss, training_op, loss_summary, init, saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def log_dir(prefix=\"\"):\n",
    "    now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "    root_logdir = \"tf_logs\"\n",
    "    if prefix:\n",
    "        prefix += \"-\"\n",
    "    name = prefix + \"run-\" + now\n",
    "    return \"{}/{}/\".format(root_logdir, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_enhanced = np.c_[X_train,\n",
    "                         np.square(X_train[:, 1]),\n",
    "                         np.square(X_train[:, 2]),\n",
    "                         X_train[:, 1] ** 3,\n",
    "                         X_train[:, 2] ** 3]\n",
    "X_test_enhanced = np.c_[X_test,\n",
    "                        np.square(X_test[:, 1]),\n",
    "                        np.square(X_test[:, 2]),\n",
    "                        X_test[:, 1] ** 3,\n",
    "                        X_test[:, 2] ** 3]\n",
    "\n",
    "nb_inputs = X_train_enhanced.shape[1]\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, nb_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"X\")\n",
    "\n",
    "logdir = log_dir(\"logreg\")\n",
    "\n",
    "y_proba, loss, training_op, loss_summary, init, saver = logistic_regression(X, y)\n",
    "\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training was interrupted. Continuing at epoch 1\n",
      "INFO:tensorflow:Restoring parameters from /tmp/my_logreg_model.ckpt\n",
      "Epoch: 500 \tLoss: 0.144789\n",
      "Epoch: 1000 \tLoss: 0.109224\n",
      "Epoch: 1500 \tLoss: 0.0925825\n",
      "Epoch: 2000 \tLoss: 0.0828035\n",
      "Epoch: 2500 \tLoss: 0.0763346\n",
      "Epoch: 3000 \tLoss: 0.0717452\n",
      "Epoch: 3500 \tLoss: 0.0683072\n",
      "Epoch: 4000 \tLoss: 0.0656737\n",
      "Epoch: 4500 \tLoss: 0.0635537\n",
      "Epoch: 5000 \tLoss: 0.0618602\n",
      "Epoch: 5500 \tLoss: 0.0604132\n",
      "Epoch: 6000 \tLoss: 0.0592299\n",
      "Epoch: 6500 \tLoss: 0.0582651\n",
      "Epoch: 7000 \tLoss: 0.0573394\n",
      "Epoch: 7500 \tLoss: 0.0565791\n",
      "Epoch: 8000 \tLoss: 0.0559283\n",
      "Epoch: 8500 \tLoss: 0.0553998\n",
      "Epoch: 9000 \tLoss: 0.0548646\n",
      "Epoch: 9500 \tLoss: 0.0543473\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "import os\n",
    "\n",
    "n_epochs = 10001\n",
    "batch_size = 500\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "checkpoint_path = \"/tmp/my_logreg_model.ckpt\"\n",
    "checkpoint_epoch_path = checkpoint_path + \".epoch\"\n",
    "final_model_path = \"./my_logreg_model\"\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    if os.path.isfile(checkpoint_epoch_path):\n",
    "        # if the checkpoint file exists, restore the model and load the epoch number\n",
    "        with open(checkpoint_epoch_path, \"rb\") as f:\n",
    "            start_epoch = int(f.read())\n",
    "        print(\"Training was interrupted. Continuing at epoch\", start_epoch)\n",
    "        saver.restore(sess, checkpoint_path)\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "        sess.run(init)\n",
    "\n",
    "    for epoch in range(start_epoch, n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = random_batch(X_train_enhanced, y_train, batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val, summary_str = sess.run([loss, loss_summary], feed_dict={X: X_test_enhanced, y: y_test})\n",
    "        file_writer.add_summary(summary_str, epoch)\n",
    "        if epoch % 500 == 0:\n",
    "            print(\"Epoch:\", epoch, \"\\tLoss:\", loss_val)\n",
    "            saver.save(sess, checkpoint_path)\n",
    "            with open(checkpoint_epoch_path, \"wb\") as f:\n",
    "                f.write(b\"%d\" % (epoch + 1))\n",
    "\n",
    "    saver.save(sess, final_model_path)\n",
    "    y_proba_val = y_proba.eval(feed_dict={X: X_test_enhanced, y: y_test})\n",
    "    os.remove(checkpoint_epoch_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = (y_proba_val >= 0.5)\n",
    "y_pred_idx = y_pred.reshape(-1) # a 1D array rather than a column vector\n",
    "plt.plot(X_test[y_pred_idx, 1], X_test[y_pred_idx, 2], 'go', label=\"Positive\")\n",
    "plt.plot(X_test[~y_pred_idx, 1], X_test[~y_pred_idx, 2], 'r^', label=\"Negative\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
